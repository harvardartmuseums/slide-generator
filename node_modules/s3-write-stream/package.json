{
  "name": "s3-write-stream",
  "description": "Pipe data straight to an S3 key of your choice",
  "version": "0.0.1",
  "main": "index.js",
  "browser": "index.js",
  "scripts": {
    "test": "node test | faucet"
  },
  "dependencies": {
    "aws-sdk": "~2.0.0-rc8",
    "through2": "~0.4.0",
    "backoff": "~2.3.0",
    "bl": "~0.7.0"
  },
  "devDependencies": {
    "request": "~2.33.0",
    "faucet": "0.0.0",
    "tape": "~2.3.2",
    "from": "~0.1.3"
  },
  "author": {
    "name": "Hugh Kennedy",
    "email": "hughskennedy@gmail.com",
    "url": "http://hughsk.io/"
  },
  "license": "MIT",
  "repository": {
    "type": "git",
    "url": "git://github.com/hughsk/s3-write-stream"
  },
  "bugs": {
    "url": "https://github.com/hughsk/s3-write-stream/issues"
  },
  "homepage": "https://github.com/hughsk/s3-write-stream",
  "keywords": [
    "s3",
    "writeable",
    "upload",
    "streaming",
    "multipart",
    "backoff",
    "retry",
    "stream"
  ],
  "readme": "# s3-write-stream [![Flattr this!](https://api.flattr.com/button/flattr-badge-large.png)](https://flattr.com/submit/auto?user_id=hughskennedy&url=http://github.com/hughsk/s3-write-stream&title=s3-write-stream&description=hughsk/s3-write-stream%20on%20GitHub&language=en_GB&tags=flattr,github,javascript&category=software)[![experimental](http://hughsk.github.io/stability-badges/dist/experimental.svg)](http://github.com/hughsk/stability-badges) #\n\nPipe data straight to an S3 key of your choice.\n\nThis is a writeable stream that takes data and uploads it to Amazon S3 using\nits [multipart upload API](http://aws.amazon.com/about-aws/whats-new/2010/11/10/Amazon-S3-Introducing-Multipart-Upload/).\nThis is ideal for handling generated content without needing to know the\ncontent's length ahead of time, and without resorting to file system hacks or\nbuffering everything before the upload.\n\nInternally, there's a fibonacci backoff handling errors, stopping the stray failed requests which tend to tear apart long-running S3 uploads.\n\nThe end result is that uploading files to S3 is as simple as this:\n\n``` javascript\nvar fs = require('fs')\nvar upload = require('s3-write-stream')({\n    accessKeyId: process.env.AWS_ACCESS_KEY\n  , secretAccessKey: process.env.AWS_SECRET_KEY\n  , Bucket: 'photo-album'\n})\n\nfs.createWriteStream(__dirname + '/photo_001.jpg')\n  .pipe(upload('images/photo_001.jpg'))\n```\n\n## Usage ##\n\n[![s3-write-stream](https://nodei.co/npm/s3-write-stream.png?mini=true)](https://nodei.co/npm/s3-write-stream)\n\n### `createStream = require('s3-write-stream')(opts)` ###\n\nInitiates the `s3-write-stream` module with your AWS configuration. The\nfollowing properties are required:\n\n* `opts.accessKeyId`: your AWS access key id.\n* `opts.secretAccessKey`: your AWS secret access id.\n\nIt's also recommended that you include `opts.Bucket` to define the default\nS3 bucket you want to upload to.\n\n### `createStream(key|opts)` ###\n\nCreates and returns a writeable stream, that you can pipe to upload to. You\ncan either:\n\n* pass the upload's `key` as a string to determine the location you\n  want to upload to. By default, files uploaded this way will be public.\n* pass in an `opts` object, which will pass those parameters on to the\n  initial upload call via [`aws-sdk`](https://github.com/aws/aws-sdk-js).\n\nNote that if you haven't already specified a default bucket, you'll need to do\nso here and hence will need to use `opts`.\n\n## License ##\n\nMIT. See [LICENSE.md](http://github.com/hughsk/s3-write-stream/blob/master/LICENSE.md) for details.\n",
  "readmeFilename": "README.md",
  "_id": "s3-write-stream@0.0.1",
  "dist": {
    "shasum": "4cfefffbdbc4d209700eec6e40841abfb0d4019f"
  },
  "_from": "s3-write-stream@",
  "_resolved": "https://registry.npmjs.org/s3-write-stream/-/s3-write-stream-0.0.1.tgz"
}
